{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Optimization and Performance Measure**\n",
        "\n",
        "Deep learning model optimization refers to the process of improving the performance, efficiency, and general characteristics of a deep learning model. Optimization is crucial for ensuring that the model performs well, uses computational resources efficiently, and problem specific requirements.\n",
        "\n",
        "Furthermore, since deep learning models are used in web applications, mobile devices, and edge devices, we want to compress the models without reducing the quality of the original models.\n",
        "\n",
        "\n",
        "# **Why models should be optimized?**\n",
        "\n",
        "There are several main ways model optimization can help with application development.\n",
        "\n",
        "## **Size reduction**\n",
        "\n",
        "Some forms of optimization can be used to reduce the size of a model. Smaller models have the following benefits:\n",
        "\n",
        "- Smaller storage size\n",
        "- Smaller download size\n",
        "- Less memory usage\n",
        "\n",
        "Quantization can reduce the size of a model in all of these cases, potentially at the expense of some accuracy. Pruning and clustering can reduce the size of a model for download by making it more easily compressible.\n",
        "\n",
        "## **Latency reduction**\n",
        "\n",
        "Latency is the amount of time it takes to run a single inference with a given model. Some forms of optimization can reduce the amount of computation required to run inference using a model, resulting in lower latency. Latency can also have an impact on power consumption.\n",
        "\n",
        "Currently, quantization can be used to reduce latency by simplifying the calculations that occur during inference, potentially at the expense of some accuracy.\n",
        "\n",
        "# **Type of optimization methods**\n",
        "\n",
        "## **Quantization**\n",
        "\n",
        "Quantization works by reducing the precision of the numbers used to represent a model's parameters, which by default are 32-bit floating point numbers. This results in a smaller model size and faster computation.\n",
        "\n",
        "## **Pruning**\n",
        "\n",
        "Pruning works by removing parameters within a model that have only a minor impact on its predictions. Pruned models are the same size on disk, and have the same runtime latency, but can be compressed more effectively. This makes pruning a useful technique for reducing model download size.\n",
        "\n",
        "\n",
        "## **Clustering**\n",
        "\n",
        "Clustering works by grouping the weights of each layer in a model into a predefined number of clusters, then sharing the centroid values for the weights belonging to each individual cluster. This reduces the number of unique weight values in a model, thus reducing its complexity.\n",
        "\n",
        "### ***The main purpose of this technique is to minimise size and boost computing speed.***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yLJqVNjrfhxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Our approaches**\n",
        "\n",
        "## **1. Mnist handwritten Dataset and develop baseline model**\n",
        "## **2. Model Optimization**\n",
        "## **- Method1: Based on three papers, Model optimization method used to compress the model**\n",
        "## **- Method 2: Optimization using Openvino**\n",
        "## **3. Performance Analysis (CPU,GPU)**\n",
        "## **- Ananlysis the performance using VTune**"
      ],
      "metadata": {
        "id": "CHJxpsQLqfTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. FashionMnist Dataset and develop baseline model**"
      ],
      "metadata": {
        "id": "ufzJjLuzstae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install necessary library\n",
        "%%time\n",
        "! pip install -q tensorflow-model-optimization tensorflow opencv-python pandas numpy matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0tV99O5t6EY",
        "outputId": "c893260d-bb89-4345-f12a-a13c05af0c24"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/242.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCPU times: user 45.2 ms, sys: 9.76 ms, total: 55 ms\n",
            "Wall time: 6.64 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIAWclCSPTlR",
        "outputId": "a9669d78-33fd-47f0-f2ba-f3c2775c4e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.61 s, sys: 433 ms, total: 4.04 s\n",
            "Wall time: 5.49 s\n"
          ]
        }
      ],
      "source": [
        "# import necessary library\n",
        "%%time\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.config.experimental.list_physical_devices('GPU'):\n",
        "    print(\"GPU available. Using GPU.\")\n",
        "    # Set GPU memory growth to avoid allocating all memory at once\n",
        "    for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "else:\n",
        "    print(\"No GPU available. Using CPU.\")"
      ],
      "metadata": {
        "id": "VIfrFiBUvhwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4c1b64-7a3c-4479-d81d-115ad3f06e01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available. Using GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Baseline Model developement using Fashion Mnist dataset (Classification problem)**"
      ],
      "metadata": {
        "id": "40YbnrlLu4zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Load MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "#print size of the dataset\n",
        "\n",
        "print(f\"Training images: {train_images.shape},Training labels: {train_labels.shape}, Test_images: {test_images.shape},Test_labels: {test_labels.shape}\")\n",
        "print(\"#\"*100)\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\n",
        "                         activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "print(model.summary())\n",
        "print(\"#\"*100)\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")\n",
        "model.save(\"baseline_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oPXmpZauuOG",
        "outputId": "b32dad69-3eb6-421e-a0dd-ec7e49b78b2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Training images: (60000, 28, 28),Training labels: (60000,), Test_images: (10000, 28, 28),Test_labels: (10000,)\n",
            "####################################################################################################\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 12)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2028)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20290     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20410 (79.73 KB)\n",
            "Trainable params: 20410 (79.73 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "####################################################################################################\n",
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 13s 6ms/step - loss: 0.5020 - accuracy: 0.8252 - val_loss: 0.3828 - val_accuracy: 0.8682\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 0.3661 - accuracy: 0.8726 - val_loss: 0.3438 - val_accuracy: 0.8815\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 0.3308 - accuracy: 0.8855 - val_loss: 0.3252 - val_accuracy: 0.8877\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3096 - accuracy: 0.8908 - val_loss: 0.3199 - val_accuracy: 0.8887\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2914 - accuracy: 0.8982 - val_loss: 0.3039 - val_accuracy: 0.8965\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2771 - accuracy: 0.9021 - val_loss: 0.2969 - val_accuracy: 0.8937\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2657 - accuracy: 0.9068 - val_loss: 0.3011 - val_accuracy: 0.8942\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2553 - accuracy: 0.9096 - val_loss: 0.2928 - val_accuracy: 0.8950\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2462 - accuracy: 0.9124 - val_loss: 0.2854 - val_accuracy: 0.9000\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2382 - accuracy: 0.9150 - val_loss: 0.2853 - val_accuracy: 0.9010\n",
            "CPU times: user 1min 5s, sys: 5.42 s, total: 1min 10s\n",
            "Wall time: 1min 15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **baseline model store and evaluation**"
      ],
      "metadata": {
        "id": "fg3sy5L-wwM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "print(\"#\"*100)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM9GRrpRvw0u",
        "outputId": "8aab7b4d-c0ba-4c84-c1b0-4b071b99c1c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.8952000141143799\n",
            "####################################################################################################\n",
            "Saving model to:  /tmp/tmpkjcqnfrc.h5\n",
            "CPU times: user 787 ms, sys: 97.8 ms, total: 885 ms\n",
            "Wall time: 785 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<timed exec>:10: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Model Optimization**"
      ],
      "metadata": {
        "id": "L4-Cf5dlzGUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.1. Method1: Based on three papers, Model optimization method used to compress the model**"
      ],
      "metadata": {
        "id": "4n-6OOKGy9qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prune and fine tune the model to 50% sparsity**"
      ],
      "metadata": {
        "id": "tdrvR4Ed034g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
        "  }\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "pruned_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "print(pruned_model.summary())\n",
        "print(\"#\"*100)\n",
        "\n",
        "# Fine-tune model\n",
        "pruned_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=3,\n",
        "  validation_split=0.1,\n",
        "  callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5twhjwFUxtE2",
        "outputId": "4cc2bfc3-87d9-43bf-a433-919bc74d876f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_reshap  (None, 28, 28, 1)         1         \n",
            " e (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 26, 26, 12)        230       \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 13, 13, 12)        1         \n",
            " oling2d (PruneLowMagnitude                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 2028)              1         \n",
            " n (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dense   (None, 10)                40572     \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40805 (159.41 KB)\n",
            "Trainable params: 20410 (79.73 KB)\n",
            "Non-trainable params: 20395 (79.69 KB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "####################################################################################################\n",
            "Epoch 1/3\n",
            "1688/1688 [==============================] - 14s 5ms/step - loss: 0.3063 - accuracy: 0.8905 - val_loss: 0.3512 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2900 - accuracy: 0.8999 - val_loss: 0.3354 - val_accuracy: 0.8805\n",
            "Epoch 3/3\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2790 - accuracy: 0.9038 - val_loss: 0.3258 - val_accuracy: 0.8858\n",
            "CPU times: user 35.1 s, sys: 3.04 s, total: 38.1 s\n",
            "Wall time: 32.5 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a6423a5aec0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#Define helper functions to calculate and print the sparsity of the model.\n",
        "\n",
        "\n",
        "def print_model_weights_sparsity(model):\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WO2lV8H91n-z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#check prunning percentage of baseline model\n",
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "print_model_weights_sparsity(stripped_pruned_model)\n",
        "\n",
        "stripped_pruned_model_copy = tf.keras.models.clone_model(stripped_pruned_model)\n",
        "stripped_pruned_model_copy.set_weights(stripped_pruned_model.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-S6ordP4l_1",
        "outputId": "e2b66144-5998-40a6-eca1-9b2d0962b45e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv2d/kernel:0: 50.00% sparsity  (54/108)\n",
            "dense/kernel:0: 50.00% sparsity  (10140/20280)\n",
            "CPU times: user 100 ms, sys: 1.82 ms, total: 102 ms\n",
            "Wall time: 104 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Apply clustering and sparsity preserving clustering and check its effect on model sparsity in both cases**"
      ],
      "metadata": {
        "id": "RCe845em48GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Clustering\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 8,\n",
        "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
        "}\n",
        "\n",
        "clustered_model = cluster_weights(stripped_pruned_model, **clustering_params)\n",
        "\n",
        "clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train clustering model:')\n",
        "clustered_model.fit(train_images, train_labels,epochs=10, validation_split=0.1)\n",
        "\n",
        "\n",
        "stripped_pruned_model.save(\"stripped_pruned_model_clustered.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dqIbfYu4sMe",
        "outputId": "140bc018-83bf-42e9-fc8d-e5638889b84b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train clustering model:\n",
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 13s 6ms/step - loss: 0.2631 - accuracy: 0.9056 - val_loss: 0.3205 - val_accuracy: 0.8875\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2559 - accuracy: 0.9082 - val_loss: 0.3176 - val_accuracy: 0.8875\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2489 - accuracy: 0.9110 - val_loss: 0.3001 - val_accuracy: 0.8933\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 0.2499 - accuracy: 0.9105 - val_loss: 0.3136 - val_accuracy: 0.8927\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2489 - accuracy: 0.9104 - val_loss: 0.3144 - val_accuracy: 0.8938\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2505 - accuracy: 0.9092 - val_loss: 0.3015 - val_accuracy: 0.8970\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 8s 4ms/step - loss: 0.2493 - accuracy: 0.9095 - val_loss: 0.3100 - val_accuracy: 0.8913\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 0.2471 - accuracy: 0.9116 - val_loss: 0.3096 - val_accuracy: 0.8932\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2400 - accuracy: 0.9134 - val_loss: 0.3033 - val_accuracy: 0.8930\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 8s 4ms/step - loss: 0.2386 - accuracy: 0.9134 - val_loss: 0.3044 - val_accuracy: 0.8900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 29s, sys: 6.53 s, total: 1min 35s\n",
            "Wall time: 1min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Sparsity preserving clustering\n",
        "from tensorflow_model_optimization.python.core.clustering.keras.experimental import (\n",
        "    cluster,\n",
        ")\n",
        "\n",
        "cluster_weights = cluster.cluster_weights\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 8,\n",
        "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS,\n",
        "  'preserve_sparsity': True\n",
        "}\n",
        "\n",
        "sparsity_clustered_model = cluster_weights(stripped_pruned_model_copy, **clustering_params)\n",
        "\n",
        "sparsity_clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train sparsity preserving clustering model:')\n",
        "sparsity_clustered_model.fit(train_images, train_labels,epochs=10, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciL1YgWy6Dtr",
        "outputId": "4edc3d4f-0fbc-4060-e4bc-ad452c2de03f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sparsity preserving clustering model:\n",
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.2612 - accuracy: 0.9058 - val_loss: 0.3090 - val_accuracy: 0.8910\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2548 - accuracy: 0.9080 - val_loss: 0.3037 - val_accuracy: 0.8930\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2491 - accuracy: 0.9104 - val_loss: 0.3036 - val_accuracy: 0.8972\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2463 - accuracy: 0.9107 - val_loss: 0.3156 - val_accuracy: 0.8885\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 0.2481 - accuracy: 0.9098 - val_loss: 0.3005 - val_accuracy: 0.8955\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2448 - accuracy: 0.9120 - val_loss: 0.3044 - val_accuracy: 0.8963\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2425 - accuracy: 0.9114 - val_loss: 0.3001 - val_accuracy: 0.8982\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2439 - accuracy: 0.9119 - val_loss: 0.3438 - val_accuracy: 0.8812\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2412 - accuracy: 0.9128 - val_loss: 0.3057 - val_accuracy: 0.8938\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2387 - accuracy: 0.9140 - val_loss: 0.3051 - val_accuracy: 0.8937\n",
            "CPU times: user 1min 39s, sys: 8 s, total: 1min 47s\n",
            "Wall time: 2min 23s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a642ed34b50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#check sparsity\n",
        "print(\"Clustered Model sparsity:\\n\")\n",
        "print_model_weights_sparsity(clustered_model)\n",
        "print(\"\\nSparsity preserved clustered Model sparsity:\\n\")\n",
        "print_model_weights_sparsity(sparsity_clustered_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_ap6zM65Cpt",
        "outputId": "30199137-643b-42f7-9f37-896211477f7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustered Model sparsity:\n",
            "\n",
            "conv2d/kernel:0: 0.00% sparsity  (0/108)\n",
            "dense/kernel:0: 0.00% sparsity  (0/20280)\n",
            "\n",
            "Sparsity preserved clustered Model sparsity:\n",
            "\n",
            "conv2d/kernel:0: 50.00% sparsity  (54/108)\n",
            "dense/kernel:0: 50.00% sparsity  (10140/20280)\n",
            "CPU times: user 8.21 ms, sys: 2.03 ms, total: 10.2 ms\n",
            "Wall time: 9.26 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%%time\n",
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in kilobytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)/1000"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QCwTf7mC6Qk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e52ac3-a995-4b5c-c3db-424476083d00"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.96 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparison of model sizes**"
      ],
      "metadata": {
        "id": "Pqcr-l34_sVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Clustered model\n",
        "clustered_model_file = 'clustered_model.h5'\n",
        "\n",
        "# Save the model.\n",
        "clustered_model.save(clustered_model_file)\n",
        "\n",
        "#Sparsity Preserve Clustered model\n",
        "sparsity_clustered_model_file = 'sparsity_clustered_model.h5'\n",
        "\n",
        "# Save the model.\n",
        "sparsity_clustered_model.save(sparsity_clustered_model_file)\n",
        "\n",
        "base_model_file = 'base_model.h5'\n",
        "model.save(base_model_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOiZviVR6Rym",
        "outputId": "0598c010-3a85-4ddd-fb31-1f5db36c36dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 56.1 ms, sys: 2.84 ms, total: 59 ms\n",
            "Wall time: 60.3 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tf_keras.src.initializers.initializers.GlorotUniform'>, which may lead to improper serialization.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tf_keras.src.initializers.initializers.Zeros'>, which may lead to improper serialization.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create a TFLite model from combining sparsity preserving weight clustering and post-training quantization**"
      ],
      "metadata": {
        "id": "gXnSp2A1AUU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "stripped_sparsity_clustered_model = tfmot.clustering.keras.strip_clustering(sparsity_clustered_model)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(stripped_sparsity_clustered_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "sparsity_clustered_quant_model = converter.convert()\n",
        "\n",
        "_, pruned_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_and_clustered_tflite_file, 'wb') as f:\n",
        "  f.write(sparsity_clustered_quant_model)\n"
      ],
      "metadata": {
        "id": "y1OPJGw-AFHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763b68bd-9150-42df-f42a-8e2244296bb6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.02 s, sys: 39.5 ms, total: 1.06 s\n",
            "Wall time: 1.09 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"Base Model size: \", get_gzipped_model_size(base_model_file), ' KB')\n",
        "print(\"Clustered Model size: \", get_gzipped_model_size(clustered_model_file), ' KB')\n",
        "print(\"Sparsity preserved clustered Model size: \", get_gzipped_model_size(sparsity_clustered_model_file), ' KB')\n",
        "print(\"Sparsity preserved clustered and quantized TFLite model size:\",\n",
        "       get_gzipped_model_size(pruned_and_clustered_tflite_file), ' KB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1RPMdW7Aeiv",
        "outputId": "d534d492-b170-4dd8-af4e-28f02f608266"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Model size:  156.828  KB\n",
            "Clustered Model size:  249.873  KB\n",
            "Sparsity preserved clustered Model size:  149.135  KB\n",
            "Sparsity preserved clustered and quantized TFLite model size: 8.33  KB\n",
            "CPU times: user 50.3 ms, sys: 3.86 ms, total: 54.1 ms\n",
            "Wall time: 55.1 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#helper function\n",
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Evaluated on {i} results so far.\")\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "GhLy3T28APfl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation of prunning and tflite model**"
      ],
      "metadata": {
        "id": "16i6KkJ6BA7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Keras model evaluation\n",
        "stripped_sparsity_clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "_, sparsity_clustered_keras_accuracy = stripped_sparsity_clustered_model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "# TFLite model evaluation\n",
        "interpreter = tf.lite.Interpreter(pruned_and_clustered_tflite_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "sparsity_clustered_tflite_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Baseline model accuracy:', baseline_model_accuracy)\n",
        "print('Pruned, clustered and quantized Keras model accuracy:', sparsity_clustered_keras_accuracy)\n",
        "print('Pruned, clustered and quantized TFLite model accuracy:', sparsity_clustered_tflite_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRr8GV2XAtA7",
        "outputId": "e53bd4c4-8a2e-4798-83d6-0745d5178c87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Baseline model accuracy: 0.8952000141143799\n",
            "Pruned, clustered and quantized Keras model accuracy: 0.891700029373169\n",
            "Pruned, clustered and quantized TFLite model accuracy: 0.8921\n",
            "CPU times: user 2.04 s, sys: 104 ms, total: 2.14 s\n",
            "Wall time: 2.08 s\n"
          ]
        }
      ]
    }
  ]
}